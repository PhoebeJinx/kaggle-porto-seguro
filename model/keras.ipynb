{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "845e32ab-4600-4db5-84c6-1847f14aa48d",
    "_uuid": "12f808bbb94d2ff51d4b8d531a32f21e179ae4cc"
   },
   "source": [
    "It seems like none of the Keras scripts published so far managed to get above 0.26. As written below, this script won't do much better either, but that is with 4 folds, and only two repeated runs and 3 epochs per fold. A proper version of this script with 5 folds and 3 repeated runs has out-of-fold CV of 0.274 and a leaderboard score of 0.270.\n",
    "\n",
    "Keep on reading for suggestions how to get this script to score better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T06:01:30.068605Z",
     "start_time": "2017-10-30T23:01:10.711918-07:00"
    },
    "_cell_guid": "be30f312-b2fb-4e5b-a0b8-9ddbbb190d2e",
    "_uuid": "7a90bcae1134c958f391542f4d67df93ed020d98",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed()\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd63fa76-0b6d-4b1b-bd9c-7dcaba0ccd40",
    "_uuid": "bc2f0776a6622aa29b628ef37a660f340337f0cc"
   },
   "source": [
    "This callback is very important. It calculates roc_auc and gini values so they can be monitored during the run. Also, it creates a log of those parameters so that they can be used for early stopping. A tip of the hat to **[Roberto](https://www.kaggle.com/rspadim)** and **[this kernel](https://www.kaggle.com/rspadim/gini-keras-callback-earlystopping-validation)** for helping me figure out the latter.\n",
    "\n",
    "*Note that this callback in combination with early stopping doesn't print well if you are using verbose=1 (moving arrow) during fitting. I recommend that you use verbose=2 in fitting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T06:01:30.099612Z",
     "start_time": "2017-10-30T23:01:30.069598-07:00"
    },
    "_cell_guid": "8d9c3461-8f27-4754-a204-a4cf82a62450",
    "_uuid": "ca16921d40817307195c9567405e4aa7c3765097",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class roc_auc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict_proba(self.x, verbose=0)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        logs['roc_auc'] = roc_auc_score(self.y, y_pred)\n",
    "        logs['norm_gini'] = ( roc_auc_score(self.y, y_pred) * 2 ) - 1\n",
    "\n",
    "        y_pred_val = self.model.predict_proba(self.x_val, verbose=0)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['roc_auc_val'] = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['norm_gini_val'] = ( roc_auc_score(self.y_val, y_pred_val) * 2 ) - 1\n",
    "\n",
    "        print('\\rroc_auc: %s - roc_auc_val: %s - norm_gini: %s - norm_gini_val: %s' % (str(round(roc,5)),str(round(roc_val,5)),str(round((roc*2-1),5)),str(round((roc_val*2-1),5))), end=10*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4000c8c-8794-45e1-9ce5-ef84f9dc13a7",
    "_uuid": "18a2e97141c98c5ea3dfa45c35e75e0257ddf20e"
   },
   "source": [
    "Housekeeping utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T06:01:30.117616Z",
     "start_time": "2017-10-30T23:01:30.101611-07:00"
    },
    "_cell_guid": "69074e99-541c-4e93-b4d8-97f7a6407465",
    "_uuid": "89ab39c0da583cf503966fa4edccfec9f25c2e50",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod(\n",
    "            (datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' %\n",
    "              (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2f346986-75c0-4bed-b4db-e7ccc99f88f8",
    "_uuid": "ea7bfad9bf8617aa9182ad7f6cd3ea9e6fb11276"
   },
   "source": [
    "I never seem to be able to write a generic routine for data loading where one would just plug in file names and everything else would be done automatically. Still trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T06:01:30.133622Z",
     "start_time": "2017-10-30T23:01:30.119617-07:00"
    },
    "_cell_guid": "8665bec9-6b3f-437a-836c-c0ee252338b8",
    "_uuid": "217687c584b7af8619705f3cf23e480bcf029e58",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train and test data path\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "\n",
    "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n",
    "    train_loader = pd.read_csv(path_train, dtype={'target': np.int8, 'id': np.int32})\n",
    "    train = train_loader.drop(['target', 'id'], axis=1)\n",
    "    train_labels = train_loader['target'].values\n",
    "    train_ids = train_loader['id'].values\n",
    "    print('\\n Shape of raw train data:', train.shape)\n",
    "\n",
    "    test_loader = pd.read_csv(path_test, dtype={'id': np.int32})\n",
    "    test = test_loader.drop(['id'], axis=1)\n",
    "    test_ids = test_loader['id'].values\n",
    "    print(' Shape of raw test data:', test.shape)\n",
    "\n",
    "    return train, train_labels, test, train_ids, test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1c0173f8-8f85-468d-97e0-6fa55c9cf640",
    "_uuid": "1e112501fd4387f197b98b72f27155981b585178"
   },
   "source": [
    "You can ignore most of the parameters below other than the top two. Obviously, more folds means longer running time, but I can tell you from experience that 10 folds with Keras will usually do better than 4. The number of \"runs\" should be in the 3-5 range. At a minimum, I suggest 5 folds and 3 independent runs per fold (which will eventually get averaged).  This is because of stochastic nature of neural networks, so one run per fold may or may not produce the best possible result.\n",
    "\n",
    "**If you can afford it, 10 folds and 5 runs per fold would be my recommendation. Be warned that it may take a day or two, even if you have a GPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T06:01:30.142624Z",
     "start_time": "2017-10-30T23:01:30.135622-07:00"
    },
    "_cell_guid": "0609e539-110a-4968-bab8-6156e3ebb904",
    "_uuid": "e34bced4579cd9b755c33c13a419f29f0ce8354f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = 15\n",
    "runs = 1\n",
    "\n",
    "cv_LL = 0\n",
    "cv_AUC = 0\n",
    "cv_gini = 0\n",
    "fpred = []\n",
    "avpred = []\n",
    "avreal = []\n",
    "avids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "988ac526-b38d-46ee-8636-c23128470b0e",
    "_uuid": "49a0ff4069fb3e38e1441d907869e3e2457fbb57"
   },
   "source": [
    "Loading data. Converting \"categorical\" variables, even though in this dataset they are actually numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T06:02:08.173113Z",
     "start_time": "2017-10-30T23:01:30.145625-07:00"
    },
    "_cell_guid": "b6cc7153-1c92-47d2-a24f-9b41668a0a90",
    "_uuid": "fea20a516b7076d491b9aa4bfe2153243e0974c8",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of raw train data: (595212, 57)\n",
      " Shape of raw test data: (892816, 57)\n",
      "\n",
      " Shape of processed train data: (595212, 227)\n",
      " Shape of processed test data: (892816, 227)\n"
     ]
    }
   ],
   "source": [
    "# Load data set and target values\n",
    "train, target, test, tr_ids, te_ids = load_data()\n",
    "n_train = train.shape[0]\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "col_to_drop = train.columns[train.columns.str.endswith('_cat')]\n",
    "col_to_dummify = train.columns[train.columns.str.endswith('_cat')].astype(str).tolist()\n",
    "\n",
    "for col in col_to_dummify:\n",
    "    dummy = pd.get_dummies(train_test[col].astype('category'))\n",
    "    columns = dummy.columns.astype(str).tolist()\n",
    "    columns = [col + '_' + w for w in columns]\n",
    "    dummy.columns = columns\n",
    "    train_test = pd.concat((train_test, dummy), axis=1)\n",
    "\n",
    "train_test.drop(col_to_dummify, axis=1, inplace=True)\n",
    "train_test_scaled, scaler = scale_data(train_test)\n",
    "train = train_test_scaled[:n_train, :]\n",
    "test = train_test_scaled[n_train:, :]\n",
    "print('\\n Shape of processed train data:', train.shape)\n",
    "print(' Shape of processed test data:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "94b32825-7e74-4f2f-8609-66eae854113f",
    "_uuid": "7de3cc91cc55f33ce70ce3acbda04fdb9c618ecc"
   },
   "source": [
    "The two parameters below are worth playing with. Larger patience gives the network a better chance to find solutions when it gets close to the local/global minimum. It also means longer training times. Batch size is one of those parameters that can always be optimized for any given dataset. If you have a GPU, larger batch sizes translate to faster training, but that may or may not be better for the quality of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T06:02:08.179116Z",
     "start_time": "2017-10-30T23:02:08.175115-07:00"
    },
    "_cell_guid": "631f1bcc-b309-449f-9595-aee7200f0210",
    "_uuid": "37113e0d59829e615f475e1ac9316c4d2097534d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patience = 10\n",
    "batchsize = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6b757c87-bdc0-4fd6-a620-9a1361aa7e0b",
    "_uuid": "f9c1cbc23ef29cc5573390df6896640d8a1da536"
   },
   "source": [
    "There are lots of comments within the code below. I think the callback section is particularly import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T15:32:25.294602Z",
     "start_time": "2017-10-30T23:02:08.183119-07:00"
    },
    "_cell_guid": "8da63d81-1961-4b91-b934-9dc7fe05d8ea",
    "_uuid": "e205d78f5cd47452a1a4fba004f9169534356a9f",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 - Run 1\n",
      "\n",
      "Train on 555530 samples, validate on 39682 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.63079 - roc_auc_val: 0.62531 - norm_gini: 0.26159 - norm_gini_val: 0.25062          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.25062, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "235s - loss: 0.1562 - acc: 0.9633 - val_loss: 0.1529 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "roc_auc: 0.63462 - roc_auc_val: 0.62943 - norm_gini: 0.26924 - norm_gini_val: 0.25886          \n",
      "Epoch 00001: norm_gini_val improved from 0.25062 to 0.25886, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "222s - loss: 0.1539 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "roc_auc: 0.6369 - roc_auc_val: 0.63287 - norm_gini: 0.27379 - norm_gini_val: 0.26574          \n",
      "Epoch 00002: norm_gini_val improved from 0.25886 to 0.26574, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "221s - loss: 0.1535 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9635\n",
      "Epoch 4/20\n",
      "roc_auc: 0.63815 - roc_auc_val: 0.63413 - norm_gini: 0.2763 - norm_gini_val: 0.26826          \n",
      "Epoch 00003: norm_gini_val improved from 0.26574 to 0.26826, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "219s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 5/20\n",
      "roc_auc: 0.60363 - roc_auc_val: 0.58781 - norm_gini: 0.20726 - norm_gini_val: 0.17561          \n",
      "Epoch 00004: norm_gini_val did not improve\n",
      "220s - loss: 0.1531 - acc: 0.9636 - val_loss: 0.1545 - val_acc: 0.9635\n",
      "Epoch 6/20\n",
      "roc_auc: 0.63851 - roc_auc_val: 0.6255 - norm_gini: 0.27702 - norm_gini_val: 0.251          \n",
      "Epoch 00005: norm_gini_val did not improve\n",
      "222s - loss: 0.1529 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9635\n",
      "Epoch 7/20\n",
      "roc_auc: 0.64531 - roc_auc_val: 0.63483 - norm_gini: 0.29062 - norm_gini_val: 0.26966          \n",
      "Epoch 00006: norm_gini_val improved from 0.26826 to 0.26966, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "226s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9635\n",
      "Epoch 8/20\n",
      "roc_auc: 0.64667 - roc_auc_val: 0.63145 - norm_gini: 0.29334 - norm_gini_val: 0.26291          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      "218s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9635\n",
      "Epoch 9/20\n",
      "roc_auc: 0.64562 - roc_auc_val: 0.6242 - norm_gini: 0.29125 - norm_gini_val: 0.24839          \n",
      "Epoch 00008: norm_gini_val did not improve\n",
      "220s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 10/20\n",
      "roc_auc: 0.64682 - roc_auc_val: 0.63548 - norm_gini: 0.29364 - norm_gini_val: 0.27096          \n",
      "Epoch 00009: norm_gini_val improved from 0.26966 to 0.27096, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "220s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9635\n",
      "Epoch 11/20\n",
      "roc_auc: 0.65301 - roc_auc_val: 0.63817 - norm_gini: 0.30601 - norm_gini_val: 0.27633          \n",
      "Epoch 00010: norm_gini_val improved from 0.27096 to 0.27633, saving model to keras-5fold-run-01-v1-fold-01-run-01.check\n",
      "219s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9635\n",
      "Epoch 12/20\n",
      "roc_auc: 0.65499 - roc_auc_val: 0.63482 - norm_gini: 0.30998 - norm_gini_val: 0.26965          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "219s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1533 - val_acc: 0.9635\n",
      "Epoch 13/20\n",
      "roc_auc: 0.65622 - roc_auc_val: 0.63603 - norm_gini: 0.31244 - norm_gini_val: 0.27206          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "220s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9635\n",
      "Epoch 14/20\n",
      "roc_auc: 0.65951 - roc_auc_val: 0.63513 - norm_gini: 0.31902 - norm_gini_val: 0.27025          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "221s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "roc_auc: 0.66084 - roc_auc_val: 0.63544 - norm_gini: 0.32168 - norm_gini_val: 0.27089          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "220s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9635\n",
      "Epoch 16/20\n",
      "roc_auc: 0.66312 - roc_auc_val: 0.63478 - norm_gini: 0.32623 - norm_gini_val: 0.26956          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      "219s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9636\n",
      "Epoch 17/20\n",
      "roc_auc: 0.66658 - roc_auc_val: 0.63396 - norm_gini: 0.33316 - norm_gini_val: 0.26792          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      "217s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9636\n",
      "Epoch 18/20\n",
      "roc_auc: 0.66685 - roc_auc_val: 0.63414 - norm_gini: 0.33371 - norm_gini_val: 0.26828          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      "218s - loss: 0.1514 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 19/20\n",
      "roc_auc: 0.66982 - roc_auc_val: 0.63118 - norm_gini: 0.33964 - norm_gini_val: 0.26236          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      "217s - loss: 0.1514 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 20/20\n",
      "roc_auc: 0.67181 - roc_auc_val: 0.63301 - norm_gini: 0.34362 - norm_gini_val: 0.26602          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      "216s - loss: 0.1513 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9635\n",
      "\n",
      " Fold 1 Run 1 Log-loss: 0.15224\n",
      " Fold 1 Run 1 AUC: 0.63817\n",
      " Fold 1 Run 1 normalized gini: 0.27633\n",
      "\n",
      " Fold 1 Log-loss: 0.15224\n",
      " Fold 1 AUC: 0.63817\n",
      " Fold 1 normalized gini: 0.27633\n",
      "\n",
      " Time taken: 1 hours 14 minutes and 41.11 seconds.\n",
      "\n",
      " Fold 2 - Run 1\n",
      "\n",
      "Train on 555530 samples, validate on 39682 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.62731 - roc_auc_val: 0.63616 - norm_gini: 0.25463 - norm_gini_val: 0.27232          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.27232, saving model to keras-5fold-run-01-v1-fold-02-run-01.check\n",
      "227s - loss: 0.1564 - acc: 0.9631 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "roc_auc: 0.6344 - roc_auc_val: 0.63714 - norm_gini: 0.26879 - norm_gini_val: 0.27428          \n",
      "Epoch 00001: norm_gini_val improved from 0.27232 to 0.27428, saving model to keras-5fold-run-01-v1-fold-02-run-01.check\n",
      "224s - loss: 0.1537 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "roc_auc: 0.63415 - roc_auc_val: 0.63578 - norm_gini: 0.26831 - norm_gini_val: 0.27155          \n",
      "Epoch 00002: norm_gini_val did not improve\n",
      "224s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9635\n",
      "Epoch 4/20\n",
      "roc_auc: 0.63652 - roc_auc_val: 0.63965 - norm_gini: 0.27304 - norm_gini_val: 0.27931          \n",
      "Epoch 00003: norm_gini_val improved from 0.27428 to 0.27931, saving model to keras-5fold-run-01-v1-fold-02-run-01.check\n",
      "225s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 5/20\n",
      "roc_auc: 0.64018 - roc_auc_val: 0.64129 - norm_gini: 0.28035 - norm_gini_val: 0.28259          \n",
      "Epoch 00004: norm_gini_val improved from 0.27931 to 0.28259, saving model to keras-5fold-run-01-v1-fold-02-run-01.check\n",
      "225s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9635\n",
      "Epoch 6/20\n",
      "roc_auc: 0.6427 - roc_auc_val: 0.64279 - norm_gini: 0.2854 - norm_gini_val: 0.28558          \n",
      "Epoch 00005: norm_gini_val improved from 0.28259 to 0.28558, saving model to keras-5fold-run-01-v1-fold-02-run-01.check\n",
      "225s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9635\n",
      "Epoch 7/20\n",
      "roc_auc: 0.64377 - roc_auc_val: 0.64409 - norm_gini: 0.28753 - norm_gini_val: 0.28819          \n",
      "Epoch 00006: norm_gini_val improved from 0.28558 to 0.28819, saving model to keras-5fold-run-01-v1-fold-02-run-01.check\n",
      "224s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9635\n",
      "Epoch 8/20\n",
      "roc_auc: 0.64563 - roc_auc_val: 0.64248 - norm_gini: 0.29125 - norm_gini_val: 0.28496          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      "224s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 9/20\n",
      "roc_auc: 0.64887 - roc_auc_val: 0.64491 - norm_gini: 0.29775 - norm_gini_val: 0.28982          \n",
      "Epoch 00008: norm_gini_val improved from 0.28819 to 0.28982, saving model to keras-5fold-run-01-v1-fold-02-run-01.check\n",
      "225s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9635\n",
      "Epoch 10/20\n",
      "roc_auc: 0.63976 - roc_auc_val: 0.63217 - norm_gini: 0.27952 - norm_gini_val: 0.26434          \n",
      "Epoch 00009: norm_gini_val did not improve\n",
      "225s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1531 - val_acc: 0.9636\n",
      "Epoch 11/20\n",
      "roc_auc: 0.65177 - roc_auc_val: 0.64178 - norm_gini: 0.30353 - norm_gini_val: 0.28356          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      "224s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1519 - val_acc: 0.9635\n",
      "Epoch 12/20\n",
      "roc_auc: 0.65455 - roc_auc_val: 0.64416 - norm_gini: 0.3091 - norm_gini_val: 0.28832          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "224s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1517 - val_acc: 0.9635\n",
      "Epoch 13/20\n",
      "roc_auc: 0.65766 - roc_auc_val: 0.64396 - norm_gini: 0.31531 - norm_gini_val: 0.28791          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "224s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9635\n",
      "Epoch 14/20\n",
      "roc_auc: 0.65701 - roc_auc_val: 0.64327 - norm_gini: 0.31403 - norm_gini_val: 0.28653          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "225s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "roc_auc: 0.66206 - roc_auc_val: 0.64318 - norm_gini: 0.32412 - norm_gini_val: 0.28636          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "225s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 16/20\n",
      "roc_auc: 0.66093 - roc_auc_val: 0.6421 - norm_gini: 0.32186 - norm_gini_val: 0.2842          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      "224s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9635\n",
      "Epoch 17/20\n",
      "roc_auc: 0.66564 - roc_auc_val: 0.64292 - norm_gini: 0.33127 - norm_gini_val: 0.28584          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      "223s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9635\n",
      "Epoch 18/20\n",
      "roc_auc: 0.65951 - roc_auc_val: 0.64271 - norm_gini: 0.31901 - norm_gini_val: 0.28543          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      "224s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1521 - val_acc: 0.9635\n",
      "Epoch 19/20\n",
      "roc_auc: 0.6681 - roc_auc_val: 0.64398 - norm_gini: 0.3362 - norm_gini_val: 0.28797          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      "224s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 20/20\n",
      "roc_auc: 0.67007 - roc_auc_val: 0.6424 - norm_gini: 0.34014 - norm_gini_val: 0.28481          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      "225s - loss: 0.1514 - acc: 0.9636 - val_loss: 0.1521 - val_acc: 0.9635\n",
      "Epoch 00019: early stopping\n",
      "\n",
      " Fold 2 Run 1 Log-loss: 0.15183\n",
      " Fold 2 Run 1 AUC: 0.64491\n",
      " Fold 2 Run 1 normalized gini: 0.28982\n",
      "\n",
      " Fold 2 Log-loss: 0.15183\n",
      " Fold 2 AUC: 0.64491\n",
      " Fold 2 normalized gini: 0.28982\n",
      "\n",
      " Time taken: 1 hours 16 minutes and 7.14 seconds.\n",
      "\n",
      " Fold 3 - Run 1\n",
      "\n",
      "Train on 555530 samples, validate on 39682 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.62816 - roc_auc_val: 0.61002 - norm_gini: 0.25632 - norm_gini_val: 0.22004          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.22004, saving model to keras-5fold-run-01-v1-fold-03-run-01.check\n",
      "234s - loss: 0.1560 - acc: 0.9633 - val_loss: 0.1546 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "roc_auc: 0.63312 - roc_auc_val: 0.61174 - norm_gini: 0.26623 - norm_gini_val: 0.22347          \n",
      "Epoch 00001: norm_gini_val improved from 0.22004 to 0.22347, saving model to keras-5fold-run-01-v1-fold-03-run-01.check\n",
      "231s - loss: 0.1538 - acc: 0.9636 - val_loss: 0.1552 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "roc_auc: 0.63762 - roc_auc_val: 0.61508 - norm_gini: 0.27524 - norm_gini_val: 0.23015          \n",
      "Epoch 00002: norm_gini_val improved from 0.22347 to 0.23015, saving model to keras-5fold-run-01-v1-fold-03-run-01.check\n",
      "231s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1539 - val_acc: 0.9635\n",
      "Epoch 4/20\n",
      "roc_auc: 0.64095 - roc_auc_val: 0.61406 - norm_gini: 0.2819 - norm_gini_val: 0.22812          \n",
      "Epoch 00003: norm_gini_val did not improve\n",
      "231s - loss: 0.1531 - acc: 0.9636 - val_loss: 0.1538 - val_acc: 0.9635\n",
      "Epoch 5/20\n",
      "roc_auc: 0.6421 - roc_auc_val: 0.61634 - norm_gini: 0.28421 - norm_gini_val: 0.23267          \n",
      "Epoch 00004: norm_gini_val improved from 0.23015 to 0.23267, saving model to keras-5fold-run-01-v1-fold-03-run-01.check\n",
      "231s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 6/20\n",
      "roc_auc: 0.64324 - roc_auc_val: 0.61342 - norm_gini: 0.28647 - norm_gini_val: 0.22684          \n",
      "Epoch 00005: norm_gini_val did not improve\n",
      "231s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1541 - val_acc: 0.9635\n",
      "Epoch 7/20\n",
      "roc_auc: 0.64609 - roc_auc_val: 0.61559 - norm_gini: 0.29218 - norm_gini_val: 0.23119          \n",
      "Epoch 00006: norm_gini_val did not improve\n",
      "230s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 8/20\n",
      "roc_auc: 0.64788 - roc_auc_val: 0.61366 - norm_gini: 0.29576 - norm_gini_val: 0.22732          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      "261s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 9/20\n",
      "roc_auc: 0.6504 - roc_auc_val: 0.61605 - norm_gini: 0.30079 - norm_gini_val: 0.2321          \n",
      "Epoch 00008: norm_gini_val did not improve\n",
      "263s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1541 - val_acc: 0.9635\n",
      "Epoch 10/20\n",
      "roc_auc: 0.65185 - roc_auc_val: 0.6166 - norm_gini: 0.30371 - norm_gini_val: 0.23319          \n",
      "Epoch 00009: norm_gini_val improved from 0.23267 to 0.23319, saving model to keras-5fold-run-01-v1-fold-03-run-01.check\n",
      "272s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 11/20\n",
      "roc_auc: 0.655 - roc_auc_val: 0.61776 - norm_gini: 0.31 - norm_gini_val: 0.23552          \n",
      "Epoch 00010: norm_gini_val improved from 0.23319 to 0.23552, saving model to keras-5fold-run-01-v1-fold-03-run-01.check\n",
      "267s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 12/20\n",
      "roc_auc: 0.65365 - roc_auc_val: 0.61664 - norm_gini: 0.3073 - norm_gini_val: 0.23328          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "261s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1535 - val_acc: 0.9635\n",
      "Epoch 13/20\n",
      "roc_auc: 0.6575 - roc_auc_val: 0.61693 - norm_gini: 0.31499 - norm_gini_val: 0.23386          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "255s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1536 - val_acc: 0.9635\n",
      "Epoch 14/20\n",
      "roc_auc: 0.66126 - roc_auc_val: 0.616 - norm_gini: 0.32251 - norm_gini_val: 0.23199          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "254s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "roc_auc: 0.66242 - roc_auc_val: 0.6165 - norm_gini: 0.32484 - norm_gini_val: 0.233          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "254s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1538 - val_acc: 0.9635\n",
      "Epoch 16/20\n",
      "roc_auc: 0.66532 - roc_auc_val: 0.61439 - norm_gini: 0.33063 - norm_gini_val: 0.22878          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      "243s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1538 - val_acc: 0.9635\n",
      "Epoch 17/20\n",
      "roc_auc: 0.66487 - roc_auc_val: 0.61582 - norm_gini: 0.32973 - norm_gini_val: 0.23164          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      "233s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1535 - val_acc: 0.9636\n",
      "Epoch 18/20\n",
      "roc_auc: 0.66874 - roc_auc_val: 0.61724 - norm_gini: 0.33748 - norm_gini_val: 0.23448          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      "239s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1535 - val_acc: 0.9635\n",
      "Epoch 19/20\n",
      "roc_auc: 0.66875 - roc_auc_val: 0.61432 - norm_gini: 0.3375 - norm_gini_val: 0.22863          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      "242s - loss: 0.1513 - acc: 0.9636 - val_loss: 0.1539 - val_acc: 0.9635\n",
      "Epoch 20/20\n",
      "roc_auc: 0.67102 - roc_auc_val: 0.61588 - norm_gini: 0.34205 - norm_gini_val: 0.23175          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      "243s - loss: 0.1513 - acc: 0.9636 - val_loss: 0.1543 - val_acc: 0.9635\n",
      "\n",
      " Fold 3 Run 1 Log-loss: 0.15339\n",
      " Fold 3 Run 1 AUC: 0.61776\n",
      " Fold 3 Run 1 normalized gini: 0.23552\n",
      "\n",
      " Fold 3 Log-loss: 0.15339\n",
      " Fold 3 AUC: 0.61776\n",
      " Fold 3 normalized gini: 0.23552\n",
      "\n",
      " Time taken: 1 hours 23 minutes and 11.48 seconds.\n",
      "\n",
      " Fold 4 - Run 1\n",
      "\n",
      "Train on 555530 samples, validate on 39682 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.62868 - roc_auc_val: 0.63252 - norm_gini: 0.25735 - norm_gini_val: 0.26503          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.26503, saving model to keras-5fold-run-01-v1-fold-04-run-01.check\n",
      "249s - loss: 0.1563 - acc: 0.9633 - val_loss: 0.1530 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "roc_auc: 0.63428 - roc_auc_val: 0.6342 - norm_gini: 0.26856 - norm_gini_val: 0.26841          \n",
      "Epoch 00001: norm_gini_val improved from 0.26503 to 0.26841, saving model to keras-5fold-run-01-v1-fold-04-run-01.check\n",
      "241s - loss: 0.1536 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "roc_auc: 0.6365 - roc_auc_val: 0.63255 - norm_gini: 0.27299 - norm_gini_val: 0.2651          \n",
      "Epoch 00002: norm_gini_val did not improve\n",
      "240s - loss: 0.1534 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 4/20\n",
      "roc_auc: 0.6387 - roc_auc_val: 0.63309 - norm_gini: 0.27739 - norm_gini_val: 0.26618          \n",
      "Epoch 00003: norm_gini_val did not improve\n",
      "240s - loss: 0.1532 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 5/20\n",
      "roc_auc: 0.64125 - roc_auc_val: 0.63405 - norm_gini: 0.28249 - norm_gini_val: 0.2681          \n",
      "Epoch 00004: norm_gini_val did not improve\n",
      "241s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1525 - val_acc: 0.9635\n",
      "Epoch 6/20\n",
      "roc_auc: 0.64317 - roc_auc_val: 0.63881 - norm_gini: 0.28634 - norm_gini_val: 0.27762          \n",
      "Epoch 00005: norm_gini_val improved from 0.26841 to 0.27762, saving model to keras-5fold-run-01-v1-fold-04-run-01.check\n",
      "240s - loss: 0.1531 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9635\n",
      "Epoch 7/20\n",
      "roc_auc: 0.64559 - roc_auc_val: 0.6347 - norm_gini: 0.29117 - norm_gini_val: 0.2694          \n",
      "Epoch 00006: norm_gini_val did not improve\n",
      "240s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9635\n",
      "Epoch 8/20\n",
      "roc_auc: 0.64675 - roc_auc_val: 0.63805 - norm_gini: 0.2935 - norm_gini_val: 0.2761          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      "240s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9635\n",
      "Epoch 9/20\n",
      "roc_auc: 0.65051 - roc_auc_val: 0.63715 - norm_gini: 0.30101 - norm_gini_val: 0.27429          \n",
      "Epoch 00008: norm_gini_val did not improve\n",
      "241s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9635\n",
      "Epoch 10/20\n",
      "roc_auc: 0.6507 - roc_auc_val: 0.63939 - norm_gini: 0.30139 - norm_gini_val: 0.27877          \n",
      "Epoch 00009: norm_gini_val improved from 0.27762 to 0.27877, saving model to keras-5fold-run-01-v1-fold-04-run-01.check\n",
      "240s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9635\n",
      "Epoch 11/20\n",
      "roc_auc: 0.65384 - roc_auc_val: 0.63763 - norm_gini: 0.30768 - norm_gini_val: 0.27526          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      "238s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9635\n",
      "Epoch 12/20\n",
      "roc_auc: 0.65478 - roc_auc_val: 0.63607 - norm_gini: 0.30955 - norm_gini_val: 0.27214          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "239s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9635\n",
      "Epoch 13/20\n",
      "roc_auc: 0.65745 - roc_auc_val: 0.63699 - norm_gini: 0.3149 - norm_gini_val: 0.27398          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "239s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9635\n",
      "Epoch 14/20\n",
      "roc_auc: 0.66009 - roc_auc_val: 0.63584 - norm_gini: 0.32018 - norm_gini_val: 0.27167          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "238s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "roc_auc: 0.66315 - roc_auc_val: 0.63527 - norm_gini: 0.3263 - norm_gini_val: 0.27055          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "237s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9635\n",
      "Epoch 16/20\n",
      "roc_auc: 0.66547 - roc_auc_val: 0.63306 - norm_gini: 0.33093 - norm_gini_val: 0.26612          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      "237s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9635\n",
      "Epoch 17/20\n",
      "roc_auc: 0.66719 - roc_auc_val: 0.63598 - norm_gini: 0.33437 - norm_gini_val: 0.27196          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      "237s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9635\n",
      "Epoch 18/20\n",
      "roc_auc: 0.67028 - roc_auc_val: 0.63488 - norm_gini: 0.34055 - norm_gini_val: 0.26977          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      "239s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9635\n",
      "Epoch 19/20\n",
      "roc_auc: 0.67077 - roc_auc_val: 0.63374 - norm_gini: 0.34155 - norm_gini_val: 0.26749          \n",
      "Epoch 00018: norm_gini_val did not improve\n",
      "238s - loss: 0.1516 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9635\n",
      "Epoch 20/20\n",
      "roc_auc: 0.67246 - roc_auc_val: 0.63501 - norm_gini: 0.34493 - norm_gini_val: 0.27002          \n",
      "Epoch 00019: norm_gini_val did not improve\n",
      "238s - loss: 0.1514 - acc: 0.9636 - val_loss: 0.1524 - val_acc: 0.9635\n",
      "\n",
      " Fold 4 Run 1 Log-loss: 0.15205\n",
      " Fold 4 Run 1 AUC: 0.63939\n",
      " Fold 4 Run 1 normalized gini: 0.27877\n",
      "\n",
      " Fold 4 Log-loss: 0.15205\n",
      " Fold 4 AUC: 0.63939\n",
      " Fold 4 normalized gini: 0.27877\n",
      "\n",
      " Time taken: 1 hours 21 minutes and 15.2 seconds.\n",
      "\n",
      " Fold 5 - Run 1\n",
      "\n",
      "Train on 555531 samples, validate on 39681 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.63078 - roc_auc_val: 0.62194 - norm_gini: 0.26156 - norm_gini_val: 0.24388          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.24388, saving model to keras-5fold-run-01-v1-fold-05-run-01.check\n",
      "245s - loss: 0.1562 - acc: 0.9633 - val_loss: 0.1533 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "roc_auc: 0.63539 - roc_auc_val: 0.62301 - norm_gini: 0.27079 - norm_gini_val: 0.24602          \n",
      "Epoch 00001: norm_gini_val improved from 0.24388 to 0.24602, saving model to keras-5fold-run-01-v1-fold-05-run-01.check\n",
      "244s - loss: 0.1537 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "roc_auc: 0.63595 - roc_auc_val: 0.6196 - norm_gini: 0.2719 - norm_gini_val: 0.2392          \n",
      "Epoch 00002: norm_gini_val did not improve\n",
      "243s - loss: 0.1534 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 4/20\n",
      "roc_auc: 0.64036 - roc_auc_val: 0.62382 - norm_gini: 0.28072 - norm_gini_val: 0.24764          \n",
      "Epoch 00003: norm_gini_val improved from 0.24602 to 0.24764, saving model to keras-5fold-run-01-v1-fold-05-run-01.check\n",
      "245s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 5/20\n",
      "roc_auc: 0.6431 - roc_auc_val: 0.62581 - norm_gini: 0.28621 - norm_gini_val: 0.25162          \n",
      "Epoch 00004: norm_gini_val improved from 0.24764 to 0.25162, saving model to keras-5fold-run-01-v1-fold-05-run-01.check\n",
      "244s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1527 - val_acc: 0.9636\n",
      "Epoch 6/20\n",
      "roc_auc: 0.6442 - roc_auc_val: 0.62511 - norm_gini: 0.2884 - norm_gini_val: 0.25022          \n",
      "Epoch 00005: norm_gini_val did not improve\n",
      "244s - loss: 0.1529 - acc: 0.9636 - val_loss: 0.1531 - val_acc: 0.9636\n",
      "Epoch 7/20\n",
      "roc_auc: 0.64681 - roc_auc_val: 0.62695 - norm_gini: 0.29362 - norm_gini_val: 0.25389          \n",
      "Epoch 00006: norm_gini_val improved from 0.25162 to 0.25389, saving model to keras-5fold-run-01-v1-fold-05-run-01.check\n",
      "244s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 8/20\n",
      "roc_auc: 0.6497 - roc_auc_val: 0.62154 - norm_gini: 0.2994 - norm_gini_val: 0.24308          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      "244s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 9/20\n",
      "roc_auc: 0.65208 - roc_auc_val: 0.62442 - norm_gini: 0.30417 - norm_gini_val: 0.24884          \n",
      "Epoch 00008: norm_gini_val did not improve\n",
      "246s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9635\n",
      "Epoch 10/20\n",
      "roc_auc: 0.65229 - roc_auc_val: 0.62107 - norm_gini: 0.30457 - norm_gini_val: 0.24215          \n",
      "Epoch 00009: norm_gini_val did not improve\n",
      "244s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9636\n",
      "Epoch 11/20\n",
      "roc_auc: 0.65514 - roc_auc_val: 0.62036 - norm_gini: 0.31028 - norm_gini_val: 0.24072          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      "244s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9636\n",
      "Epoch 12/20\n",
      "roc_auc: 0.65728 - roc_auc_val: 0.62296 - norm_gini: 0.31455 - norm_gini_val: 0.24592          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "244s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1531 - val_acc: 0.9636\n",
      "Epoch 13/20\n",
      "roc_auc: 0.65747 - roc_auc_val: 0.62089 - norm_gini: 0.31495 - norm_gini_val: 0.24177          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "244s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1536 - val_acc: 0.9636\n",
      "Epoch 14/20\n",
      "roc_auc: 0.66089 - roc_auc_val: 0.6199 - norm_gini: 0.32178 - norm_gini_val: 0.2398          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "244s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1531 - val_acc: 0.9635\n",
      "Epoch 15/20\n",
      "roc_auc: 0.66524 - roc_auc_val: 0.62078 - norm_gini: 0.33047 - norm_gini_val: 0.24157          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "245s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1531 - val_acc: 0.9636\n",
      "Epoch 16/20\n",
      "roc_auc: 0.66618 - roc_auc_val: 0.61973 - norm_gini: 0.33235 - norm_gini_val: 0.23945          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      "246s - loss: 0.1517 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9635\n",
      "Epoch 17/20\n",
      "roc_auc: 0.67091 - roc_auc_val: 0.61924 - norm_gini: 0.34181 - norm_gini_val: 0.23848          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      "245s - loss: 0.1515 - acc: 0.9636 - val_loss: 0.1534 - val_acc: 0.9636\n",
      "Epoch 18/20\n",
      "roc_auc: 0.67126 - roc_auc_val: 0.61655 - norm_gini: 0.34252 - norm_gini_val: 0.23309          \n",
      "Epoch 00017: norm_gini_val did not improve\n",
      "246s - loss: 0.1515 - acc: 0.9636 - val_loss: 0.1531 - val_acc: 0.9636\n",
      "Epoch 00017: early stopping\n",
      "\n",
      " Fold 5 Run 1 Log-loss: 0.15297\n",
      " Fold 5 Run 1 AUC: 0.62695\n",
      " Fold 5 Run 1 normalized gini: 0.25389\n",
      "\n",
      " Fold 5 Log-loss: 0.15297\n",
      " Fold 5 AUC: 0.62695\n",
      " Fold 5 normalized gini: 0.25389\n",
      "\n",
      " Time taken: 1 hours 14 minutes and 48.01 seconds.\n",
      "\n",
      " Fold 6 - Run 1\n",
      "\n",
      "Train on 555531 samples, validate on 39681 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.63007 - roc_auc_val: 0.6199 - norm_gini: 0.26014 - norm_gini_val: 0.23981          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.23981, saving model to keras-5fold-run-01-v1-fold-06-run-01.check\n",
      "261s - loss: 0.1564 - acc: 0.9633 - val_loss: 0.1533 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "roc_auc: 0.63452 - roc_auc_val: 0.624 - norm_gini: 0.26905 - norm_gini_val: 0.24799          \n",
      "Epoch 00001: norm_gini_val improved from 0.23981 to 0.24799, saving model to keras-5fold-run-01-v1-fold-06-run-01.check\n",
      "251s - loss: 0.1537 - acc: 0.9636 - val_loss: 0.1533 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "roc_auc: 0.63753 - roc_auc_val: 0.62836 - norm_gini: 0.27506 - norm_gini_val: 0.25672          \n",
      "Epoch 00002: norm_gini_val improved from 0.24799 to 0.25672, saving model to keras-5fold-run-01-v1-fold-06-run-01.check\n",
      "253s - loss: 0.1534 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 4/20\n",
      "roc_auc: 0.64088 - roc_auc_val: 0.62913 - norm_gini: 0.28176 - norm_gini_val: 0.25826          \n",
      "Epoch 00003: norm_gini_val improved from 0.25672 to 0.25826, saving model to keras-5fold-run-01-v1-fold-06-run-01.check\n",
      "256s - loss: 0.1533 - acc: 0.9636 - val_loss: 0.1533 - val_acc: 0.9636\n",
      "Epoch 5/20\n",
      "roc_auc: 0.64102 - roc_auc_val: 0.6258 - norm_gini: 0.28205 - norm_gini_val: 0.2516          \n",
      "Epoch 00004: norm_gini_val did not improve\n",
      "256s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 6/20\n",
      "roc_auc: 0.64486 - roc_auc_val: 0.62601 - norm_gini: 0.28972 - norm_gini_val: 0.25202          \n",
      "Epoch 00005: norm_gini_val did not improve\n",
      "253s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 7/20\n",
      "roc_auc: 0.62834 - roc_auc_val: 0.60427 - norm_gini: 0.25669 - norm_gini_val: 0.20854          \n",
      "Epoch 00006: norm_gini_val did not improve\n",
      "251s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1547 - val_acc: 0.9636\n",
      "Epoch 8/20\n",
      "roc_auc: 0.62743 - roc_auc_val: 0.60181 - norm_gini: 0.25486 - norm_gini_val: 0.20362          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      "253s - loss: 0.1526 - acc: 0.9636 - val_loss: 0.1549 - val_acc: 0.9636\n",
      "Epoch 9/20\n",
      "roc_auc: 0.65042 - roc_auc_val: 0.62601 - norm_gini: 0.30083 - norm_gini_val: 0.25202          \n",
      "Epoch 00008: norm_gini_val did not improve\n",
      "253s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9636\n",
      "Epoch 10/20\n",
      "roc_auc: 0.65296 - roc_auc_val: 0.62724 - norm_gini: 0.30592 - norm_gini_val: 0.25448          \n",
      "Epoch 00009: norm_gini_val did not improve\n",
      "252s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1533 - val_acc: 0.9636\n",
      "Epoch 11/20\n",
      "roc_auc: 0.65561 - roc_auc_val: 0.62658 - norm_gini: 0.31122 - norm_gini_val: 0.25316          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      "252s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9636\n",
      "Epoch 12/20\n",
      "roc_auc: 0.65822 - roc_auc_val: 0.62604 - norm_gini: 0.31644 - norm_gini_val: 0.25207          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "252s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 13/20\n",
      "roc_auc: 0.66117 - roc_auc_val: 0.62632 - norm_gini: 0.32234 - norm_gini_val: 0.25264          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "251s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 14/20\n",
      "roc_auc: 0.66153 - roc_auc_val: 0.62242 - norm_gini: 0.32306 - norm_gini_val: 0.24485          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "253s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9636\n",
      "Epoch 15/20\n",
      "roc_auc: 0.66386 - roc_auc_val: 0.62691 - norm_gini: 0.32772 - norm_gini_val: 0.25383          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "254s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9636\n",
      "Epoch 00014: early stopping\n",
      "\n",
      " Fold 6 Run 1 Log-loss: 0.15326\n",
      " Fold 6 Run 1 AUC: 0.62913\n",
      " Fold 6 Run 1 normalized gini: 0.25826\n",
      "\n",
      " Fold 6 Log-loss: 0.15326\n",
      " Fold 6 AUC: 0.62913\n",
      " Fold 6 normalized gini: 0.25826\n",
      "\n",
      " Time taken: 1 hours 4 minutes and 46.95 seconds.\n",
      "\n",
      " Fold 7 - Run 1\n",
      "\n",
      "Train on 555531 samples, validate on 39681 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.62846 - roc_auc_val: 0.63874 - norm_gini: 0.25692 - norm_gini_val: 0.27747          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.27747, saving model to keras-5fold-run-01-v1-fold-07-run-01.check\n",
      "265s - loss: 0.1563 - acc: 0.9632 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "roc_auc: 0.60699 - roc_auc_val: 0.61116 - norm_gini: 0.21398 - norm_gini_val: 0.22233          \n",
      "Epoch 00001: norm_gini_val did not improve\n",
      "261s - loss: 0.1538 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "roc_auc: 0.63377 - roc_auc_val: 0.63695 - norm_gini: 0.26753 - norm_gini_val: 0.2739          \n",
      "Epoch 00002: norm_gini_val did not improve\n",
      "263s - loss: 0.1535 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 4/20\n",
      "roc_auc: 0.63866 - roc_auc_val: 0.64094 - norm_gini: 0.27732 - norm_gini_val: 0.28189          \n",
      "Epoch 00003: norm_gini_val improved from 0.27747 to 0.28189, saving model to keras-5fold-run-01-v1-fold-07-run-01.check\n",
      "262s - loss: 0.1532 - acc: 0.9636 - val_loss: 0.1526 - val_acc: 0.9636\n",
      "Epoch 5/20\n",
      "roc_auc: 0.64067 - roc_auc_val: 0.6404 - norm_gini: 0.28134 - norm_gini_val: 0.28081          \n",
      "Epoch 00004: norm_gini_val did not improve\n",
      "261s - loss: 0.1531 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 6/20\n",
      "roc_auc: 0.64345 - roc_auc_val: 0.64194 - norm_gini: 0.28689 - norm_gini_val: 0.28387          \n",
      "Epoch 00005: norm_gini_val improved from 0.28189 to 0.28387, saving model to keras-5fold-run-01-v1-fold-07-run-01.check\n",
      "262s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 7/20\n",
      "roc_auc: 0.64441 - roc_auc_val: 0.6413 - norm_gini: 0.28883 - norm_gini_val: 0.2826          \n",
      "Epoch 00006: norm_gini_val did not improve\n",
      "261s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 8/20\n",
      "roc_auc: 0.64797 - roc_auc_val: 0.64101 - norm_gini: 0.29593 - norm_gini_val: 0.28202          \n",
      "Epoch 00007: norm_gini_val did not improve\n",
      "262s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9636\n",
      "Epoch 9/20\n",
      "roc_auc: 0.65013 - roc_auc_val: 0.63683 - norm_gini: 0.30027 - norm_gini_val: 0.27366          \n",
      "Epoch 00008: norm_gini_val did not improve\n",
      "264s - loss: 0.1525 - acc: 0.9636 - val_loss: 0.1520 - val_acc: 0.9636\n",
      "Epoch 10/20\n",
      "roc_auc: 0.65232 - roc_auc_val: 0.63822 - norm_gini: 0.30464 - norm_gini_val: 0.27644          \n",
      "Epoch 00009: norm_gini_val did not improve\n",
      "275s - loss: 0.1524 - acc: 0.9636 - val_loss: 0.1521 - val_acc: 0.9636\n",
      "Epoch 11/20\n",
      "roc_auc: 0.65267 - roc_auc_val: 0.63788 - norm_gini: 0.30535 - norm_gini_val: 0.27576          \n",
      "Epoch 00010: norm_gini_val did not improve\n",
      "275s - loss: 0.1523 - acc: 0.9636 - val_loss: 0.1521 - val_acc: 0.9636\n",
      "Epoch 12/20\n",
      "roc_auc: 0.65666 - roc_auc_val: 0.63962 - norm_gini: 0.31331 - norm_gini_val: 0.27923          \n",
      "Epoch 00011: norm_gini_val did not improve\n",
      "276s - loss: 0.1522 - acc: 0.9636 - val_loss: 0.1522 - val_acc: 0.9636\n",
      "Epoch 13/20\n",
      "roc_auc: 0.65576 - roc_auc_val: 0.63996 - norm_gini: 0.31152 - norm_gini_val: 0.27991          \n",
      "Epoch 00012: norm_gini_val did not improve\n",
      "266s - loss: 0.1521 - acc: 0.9636 - val_loss: 0.1518 - val_acc: 0.9636\n",
      "Epoch 14/20\n",
      "roc_auc: 0.65893 - roc_auc_val: 0.6376 - norm_gini: 0.31787 - norm_gini_val: 0.2752          \n",
      "Epoch 00013: norm_gini_val did not improve\n",
      "264s - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1523 - val_acc: 0.9636\n",
      "Epoch 15/20\n",
      "roc_auc: 0.66143 - roc_auc_val: 0.6346 - norm_gini: 0.32286 - norm_gini_val: 0.2692          \n",
      "Epoch 00014: norm_gini_val did not improve\n",
      "265s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1521 - val_acc: 0.9636\n",
      "Epoch 16/20\n",
      "roc_auc: 0.66447 - roc_auc_val: 0.64126 - norm_gini: 0.32895 - norm_gini_val: 0.28251          \n",
      "Epoch 00015: norm_gini_val did not improve\n",
      "264s - loss: 0.1519 - acc: 0.9636 - val_loss: 0.1517 - val_acc: 0.9636\n",
      "Epoch 17/20\n",
      "roc_auc: 0.66513 - roc_auc_val: 0.64031 - norm_gini: 0.33026 - norm_gini_val: 0.28063          \n",
      "Epoch 00016: norm_gini_val did not improve\n",
      "269s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.1517 - val_acc: 0.9636\n",
      "Epoch 00016: early stopping\n",
      "\n",
      " Fold 7 Run 1 Log-loss: 0.15235\n",
      " Fold 7 Run 1 AUC: 0.64194\n",
      " Fold 7 Run 1 normalized gini: 0.28387\n",
      "\n",
      " Fold 7 Log-loss: 0.15235\n",
      " Fold 7 AUC: 0.64194\n",
      " Fold 7 normalized gini: 0.28387\n",
      "\n",
      " Time taken: 1 hours 16 minutes and 50.76 seconds.\n",
      "\n",
      " Fold 8 - Run 1\n",
      "\n",
      "Train on 555531 samples, validate on 39681 samples\n",
      "Epoch 1/20\n",
      "roc_auc: 0.6184 - roc_auc_val: 0.60649 - norm_gini: 0.23681 - norm_gini_val: 0.21298          \n",
      "Epoch 00000: norm_gini_val improved from -inf to 0.21298, saving model to keras-5fold-run-01-v1-fold-08-run-01.check\n",
      "280s - loss: 0.1562 - acc: 0.9633 - val_loss: 0.1539 - val_acc: 0.9636\n",
      "Epoch 2/20\n",
      "roc_auc: 0.63371 - roc_auc_val: 0.62067 - norm_gini: 0.26742 - norm_gini_val: 0.24135          \n",
      "Epoch 00001: norm_gini_val improved from 0.21298 to 0.24135, saving model to keras-5fold-run-01-v1-fold-08-run-01.check\n",
      "280s - loss: 0.1537 - acc: 0.9636 - val_loss: 0.1538 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "roc_auc: 0.63603 - roc_auc_val: 0.62447 - norm_gini: 0.27207 - norm_gini_val: 0.24894          \n",
      "Epoch 00002: norm_gini_val improved from 0.24135 to 0.24894, saving model to keras-5fold-run-01-v1-fold-08-run-01.check\n",
      "282s - loss: 0.1534 - acc: 0.9636 - val_loss: 0.1537 - val_acc: 0.9636\n",
      "Epoch 4/20\n",
      "roc_auc: 0.63914 - roc_auc_val: 0.62358 - norm_gini: 0.27829 - norm_gini_val: 0.24716          \n",
      "Epoch 00003: norm_gini_val did not improve\n",
      "278s - loss: 0.1532 - acc: 0.9636 - val_loss: 0.1528 - val_acc: 0.9636\n",
      "Epoch 5/20\n",
      "roc_auc: 0.63841 - roc_auc_val: 0.62096 - norm_gini: 0.27681 - norm_gini_val: 0.24191          \n",
      "Epoch 00004: norm_gini_val did not improve\n",
      "279s - loss: 0.1530 - acc: 0.9636 - val_loss: 0.1538 - val_acc: 0.9636\n",
      "Epoch 6/20\n",
      "roc_auc: 0.64363 - roc_auc_val: 0.62784 - norm_gini: 0.28726 - norm_gini_val: 0.25569          \n",
      "Epoch 00005: norm_gini_val improved from 0.24894 to 0.25569, saving model to keras-5fold-run-01-v1-fold-08-run-01.check\n",
      "280s - loss: 0.1529 - acc: 0.9636 - val_loss: 0.1529 - val_acc: 0.9636\n",
      "Epoch 7/20\n",
      "roc_auc: 0.64253 - roc_auc_val: 0.6247 - norm_gini: 0.28507 - norm_gini_val: 0.2494          \n",
      "Epoch 00006: norm_gini_val did not improve\n",
      "285s - loss: 0.1528 - acc: 0.9636 - val_loss: 0.1530 - val_acc: 0.9636\n",
      "Epoch 8/20\n",
      "roc_auc: 0.64699 - roc_auc_val: 0.63077 - norm_gini: 0.29397 - norm_gini_val: 0.26154          \n",
      "Epoch 00007: norm_gini_val improved from 0.25569 to 0.26154, saving model to keras-5fold-run-01-v1-fold-08-run-01.check\n",
      "280s - loss: 0.1527 - acc: 0.9636 - val_loss: 0.1535 - val_acc: 0.9636\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6037559d56c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m             callbacks=callbacks)\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;31m# We want the best saved model - not the last one where the training stopped. So we delete the old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's split the data into folds. I always use the same random number for reproducibility, \n",
    "# and suggest that you do the same (you certainly don't have to use 1001).\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, random_state=1001)\n",
    "starttime = timer(None)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, target)):\n",
    "    start_time = timer(None)\n",
    "    X_train, X_val = train[train_index], train[test_index]\n",
    "    y_train, y_val = target[train_index], target[test_index]\n",
    "    train_ids, val_ids = tr_ids[train_index], tr_ids[test_index]\n",
    "    \n",
    "# This is where we define and compile the model. These parameters are not optimal, as they were chosen \n",
    "# to get a notebook to complete in 60 minutes. Other than leaving BatchNormalization and last sigmoid \n",
    "# activation alone, virtually everything else can be optimized: number of neurons, types of initializers, \n",
    "# activation functions, dropout values. The same goes for the optimizer at the end.\n",
    "\n",
    "#########\n",
    "# Never move this model definition to the beginning of the file or anywhere else outside of this loop. \n",
    "# The model needs to be initialized anew every time you run a different fold. If not, it will continue \n",
    "# the training from a previous model, and that is not what you want.\n",
    "#########\n",
    "\n",
    "    # This definition must be within the for loop or else it will continue training previous model\n",
    "    def baseline_model():\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Dense(\n",
    "                512,\n",
    "                input_dim=X_train.shape[1],\n",
    "                kernel_initializer='glorot_normal',\n",
    "                ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('elu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(256, kernel_initializer='glorot_normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('elu'))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Dense(128, kernel_initializer='glorot_normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('elu'))\n",
    "        #model.add(Dropout(0.15))\n",
    "        model.add(Dense(64, kernel_initializer='glorot_normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('elu'))\n",
    "        #model.add(Dropout(0.1))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer='adam', metrics = ['accuracy'], loss='binary_crossentropy')\n",
    "\n",
    "        return model\n",
    "\n",
    "# This is where we repeat the runs for each fold. If you choose runs=1 above, it will run a \n",
    "# regular N-fold procedure.\n",
    "\n",
    "#########\n",
    "# It is important to leave the call to random seed here, so each run starts with a different seed.\n",
    "#########\n",
    "\n",
    "    for run in range(runs):\n",
    "        print('\\n Fold %d - Run %d\\n' % ((i + 1), (run + 1)))\n",
    "        np.random.seed()\n",
    "\n",
    "# Lots to unpack here.\n",
    "\n",
    "# The first callback prints out roc_auc and gini values at the end of each epoch. It must be listed \n",
    "# before the EarlyStopping callback, which monitors gini values saved in the previous callback. Make \n",
    "# sure to set the mode to \"max\" because the default value (\"auto\") will not handle gini properly \n",
    "# (it will act as if the model is not improving even when roc/gini go up).\n",
    "\n",
    "# CSVLogger creates a record of all iterations. Not really needed but it doesn't hurt to have it.\n",
    "\n",
    "# ModelCheckpoint saves a model each time gini improves. Its mode also must be set to \"max\" for reasons \n",
    "# explained above.\n",
    "\n",
    "        callbacks = [\n",
    "            roc_auc_callback(training_data=(X_train, y_train),validation_data=(X_val, y_val)),  # call this before EarlyStopping\n",
    "            EarlyStopping(monitor='norm_gini_val', patience=patience, mode='max', verbose=1),\n",
    "            CSVLogger('keras-5fold-run-01-v1-epochs.log', separator=',', append=False),\n",
    "            ModelCheckpoint(\n",
    "                    'keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check',\n",
    "                    monitor='norm_gini_val', mode='max', # mode must be set to max or Keras will be confused\n",
    "                    save_best_only=True,\n",
    "                    verbose=1)\n",
    "        ]\n",
    "\n",
    "# The classifier is defined here. Epochs should be be set to a very large number (not 3 like below) which \n",
    "# will never be reached anyway because of early stopping. I usually put 5000 there. Because why not.\n",
    "\n",
    "        nnet = KerasClassifier(\n",
    "            build_fn=baseline_model,\n",
    "# Epoch needs to be set to a very large number ; early stopping will prevent it from reaching\n",
    "#            epochs=5000,\n",
    "            epochs=20,\n",
    "            batch_size=batchsize,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=2,\n",
    "            shuffle=True,\n",
    "            callbacks=callbacks)\n",
    "\n",
    "        fit = nnet.fit(X_train, y_train)\n",
    "        \n",
    "# We want the best saved model - not the last one where the training stopped. So we delete the old \n",
    "# model instance and load the model from the last saved checkpoint. Next we predict values both for \n",
    "# validation and test data, and create a summary of parameters for each run.\n",
    "\n",
    "        del nnet\n",
    "        nnet = load_model('keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check')\n",
    "        scores_val_run = nnet.predict_proba(X_val, verbose=0)\n",
    "        LL_run = log_loss(y_val, scores_val_run)\n",
    "        print('\\n Fold %d Run %d Log-loss: %.5f' % ((i + 1), (run + 1), LL_run))\n",
    "        AUC_run = roc_auc_score(y_val, scores_val_run)\n",
    "        print(' Fold %d Run %d AUC: %.5f' % ((i + 1), (run + 1), AUC_run))\n",
    "        print(' Fold %d Run %d normalized gini: %.5f' % ((i + 1), (run + 1), AUC_run*2-1))\n",
    "        y_pred_run = nnet.predict_proba(test, verbose=0)\n",
    "        if run > 0:\n",
    "            scores_val = scores_val + scores_val_run\n",
    "            y_pred = y_pred + y_pred_run\n",
    "        else:\n",
    "            scores_val = scores_val_run\n",
    "            y_pred = y_pred_run\n",
    "            \n",
    "# We average all runs from the same fold and provide a parameter summary for each fold. Unless something \n",
    "# is wrong, the numbers printed here should be better than any of the individual runs.\n",
    "\n",
    "    scores_val = scores_val / runs\n",
    "    y_pred = y_pred / runs\n",
    "    LL = log_loss(y_val, scores_val)\n",
    "    print('\\n Fold %d Log-loss: %.5f' % ((i + 1), LL))\n",
    "    AUC = roc_auc_score(y_val, scores_val)\n",
    "    print(' Fold %d AUC: %.5f' % ((i + 1), AUC))\n",
    "    print(' Fold %d normalized gini: %.5f' % ((i + 1), AUC*2-1))\n",
    "    timer(start_time)\n",
    "    \n",
    "# We add up predictions on the test data for each fold. Create out-of-fold predictions for validation data.\n",
    "\n",
    "    if i > 0:\n",
    "        fpred = pred + y_pred\n",
    "        avreal = np.concatenate((avreal, y_val), axis=0)\n",
    "        avpred = np.concatenate((avpred, scores_val), axis=0)\n",
    "        avids = np.concatenate((avids, val_ids), axis=0)\n",
    "    else:\n",
    "        fpred = y_pred\n",
    "        avreal = y_val\n",
    "        avpred = scores_val\n",
    "        avids = val_ids\n",
    "    pred = fpred\n",
    "    cv_LL = cv_LL + LL\n",
    "    cv_AUC = cv_AUC + AUC\n",
    "    cv_gini = cv_gini + (AUC*2-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a14d6cf9-abe2-46d0-9d7d-c3d07f555748",
    "_uuid": "b0fc6c40b88ab16828fb041bb64510a6dab44d27"
   },
   "source": [
    "Here we average all the predictions and provide the final summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T15:32:25.296602Z",
     "start_time": "2017-10-31T06:01:10.733Z"
    },
    "_cell_guid": "ffee9fa9-5ff7-41df-8702-e8bf0c386eb6",
    "_uuid": "ca37252600dc011cd9bc354fc702efd76e0324f2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LL_oof = log_loss(avreal, avpred)\n",
    "print('\\n Average Log-loss: %.5f' % (cv_LL/folds))\n",
    "print(' Out-of-fold Log-loss: %.5f' % LL_oof)\n",
    "AUC_oof = roc_auc_score(avreal, avpred)\n",
    "print('\\n Average AUC: %.5f' % (cv_AUC/folds))\n",
    "print(' Out-of-fold AUC: %.5f' % AUC_oof)\n",
    "print('\\n Average normalized gini: %.5f' % (cv_gini/folds))\n",
    "print(' Out-of-fold normalized gini: %.5f' % (AUC_oof*2-1))\n",
    "score = str(round((AUC_oof*2-1), 5))\n",
    "timer(starttime)\n",
    "mpred = pred / folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd1bd64e-fdea-4b1b-88ca-d469b7013bed",
    "_uuid": "61295f2ab3eabbe49441bd7e1b47736f3c342d6d"
   },
   "source": [
    "Save the file with out-of-fold predictions. For easier book-keeping, file names have the out-of-fold gini score and are are tagged by date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T15:32:25.297602Z",
     "start_time": "2017-10-31T06:01:10.735Z"
    },
    "_cell_guid": "e9914308-7d3b-4eef-8ea0-65532d1b4c21",
    "_uuid": "3e20f234c25aaa7302f8a9ed7b752cdaed415b9a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('#\\n Writing results')\n",
    "now = datetime.now()\n",
    "oof_result = pd.DataFrame(avreal, columns=['target'])\n",
    "oof_result['prediction'] = avpred\n",
    "oof_result['id'] = avids\n",
    "oof_result.sort_values('id', ascending=True, inplace=True)\n",
    "oof_result = oof_result.set_index('id')\n",
    "sub_file = 'train_5fold-keras-run-01-v1-oof_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n",
    "print('\\n Writing out-of-fold file:  %s' % sub_file)\n",
    "oof_result.to_csv(sub_file, index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72a76239-2c3e-4fd1-b280-3862755106be",
    "_uuid": "f4d9e51f7ea16afbb5c18886c3fddd48bbd55674"
   },
   "source": [
    "Save the final prediction. This is the one to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T15:32:25.298602Z",
     "start_time": "2017-10-31T06:01:10.737Z"
    },
    "_cell_guid": "30446b64-aec5-45da-bf09-91fac68ae6eb",
    "_uuid": "61a7063ce1fb44e4a79a1a52ae12db2600000df5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(mpred, columns=['target'])\n",
    "result['id'] = te_ids\n",
    "result = result.set_index('id')\n",
    "print('\\n First 10 lines of your 5-fold average prediction:\\n')\n",
    "print(result.head(10))\n",
    "sub_file = 'submission_5fold-average-keras-run-01-v1_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n",
    "print('\\n Writing submission:  %s' % sub_file)\n",
    "result.to_csv(sub_file, index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a4920de55aa2ab34a7db54f88c5768defe37198",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
